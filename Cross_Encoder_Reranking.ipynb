{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers chromadb langchain\n",
        "# 3.9 version"
      ],
      "metadata": {
        "id": "BVqN6x5XRXm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_utils import load_chroma, word_wrap, project_embeddings\n",
        "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_iEKLfA9TFcK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_function = SentenceTransformerEmbeddingFunction()\n",
        "chroma_collection = load_chroma(filename='rag_paper.pdf', collection_name='rag_paper', embedding_function=embedding_function)\n",
        "chroma_collection.count()"
      ],
      "metadata": {
        "id": "ObuaUN68ciAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTdZzyrRC7P",
        "outputId": "600a28df-8654-48c9-bff7-c1637f7fcd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [[query, doc] for doc in retrieved_documents]\n",
        "scores = cross_encoder.predict(pairs)\n",
        "print(\"Scores:\")\n",
        "for score in scores:\n",
        "    print(score)"
      ],
      "metadata": {
        "id": "_nxedk6-dCjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"New Ordering:\")\n",
        "for o in np.argsort(scores)[::-1]:\n",
        "    print(o+1)\n"
      ],
      "metadata": {
        "id": "Oao1zfBQdGNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-ranking with Query Expansion\n",
        "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
        "generated_queries = [\n",
        "    \"What were the major drivers of revenue growth?\",\n",
        "    \"Were there any new product launches that contributed to the increase in revenue?\",\n",
        "    \"Did any changes in pricing or promotions impact the revenue growth?\",\n",
        "    \"What were the key market trends that facilitated the increase in revenue?\",\n",
        "    \"Did any acquisitions or partnerships contribute to the revenue growth?\"\n",
        "]\n",
        "\n",
        "queries = [original_query] + generated_queries\n",
        "\n",
        "results = chroma_collection.query(query_texts=queries, n_results=10, include=['documents', 'embeddings'])\n",
        "retrieved_documents = results['documents']\n",
        "\n",
        "# Deduplicate the retrieved documents\n",
        "unique_documents = set()\n",
        "for documents in retrieved_documents:\n",
        "    for document in documents:\n",
        "        unique_documents.add(document)\n",
        "\n",
        "unique_documents = list(unique_documents)\n",
        "\n",
        "pairs = []\n",
        "for doc in unique_documents:\n",
        "    pairs.append([original_query, doc])\n",
        "\n",
        "scores = cross_encoder.predict(pairs)\n",
        "\n",
        "\n",
        "print(\"Scores:\")\n",
        "for score in scores:\n",
        "    print(score)\n",
        "\n",
        "print(\"New Ordering:\")\n",
        "for o in np.argsort(scores)[::-1]:\n",
        "    print(o)"
      ],
      "metadata": {
        "id": "W6jhH8xjc3ZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}